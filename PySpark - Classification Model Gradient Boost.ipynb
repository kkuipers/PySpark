{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case description\n",
    "\n",
    "A supermarket is offering a new line of organic products. The supermarket's management wants to determine which customers are likely to purchase these products.\n",
    "The supermarket has a customer loyalty program. As an initial buyer incentive plan, the supermarket provided coupons for the organic products to all of the loyalty program participants and collected data that includes whether these customers purchased any of the organic products.\n",
    "The ORGANICS data set contains 13 variables and 22222 observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Description\n",
    "The variables in the data set are shown below with the appropriate roles and levels:\n",
    "![Organics description](organics.png)\n",
    "The variables in this dataset has been classified into two categories: interval (i.e., real-valued) vs. nominal (i.e., categorical). Please note in this dataset, you have two dependent variables: TargetBuy (a binary variable) and TargetAmt (an interval variable). You need to deal with the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Goal is predict if the customer will buy organic food or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+----------+---------------+---------+----------+------------+---------+---------+--------+---------+---------+\n",
      "|   ID|DemAffl|DemAge|DemCluster|DemClusterGroup|DemGender|    DemReg|    DemTVReg|PromClass|PromSpend|PromTime|TargetBuy|TargetAmt|\n",
      "+-----+-------+------+----------+---------------+---------+----------+------------+---------+---------+--------+---------+---------+\n",
      "|  140|     10|    76|        16|              C|        U|  Midlands|Wales & West|     Gold|  16000.0|       4|        0|        0|\n",
      "|  620|      4|    49|        35|              D|        U|  Midlands|Wales & West|     Gold|   6000.0|       5|        0|        0|\n",
      "|  868|      5|    70|        27|              D|        F|  Midlands|Wales & West|   Silver|     0.02|       8|        1|        1|\n",
      "| 1120|     10|    65|        51|              F|        M|  Midlands|    Midlands|      Tin|     0.01|       7|        1|        1|\n",
      "| 2313|     11|    68|         4|              A|        F|  Midlands|    Midlands|      Tin|     0.01|       8|        0|        0|\n",
      "| 2771|      9|    72|        28|              D|        U|     North|      N West| Platinum| 20759.81|       3|        0|        0|\n",
      "| 3131|     11|    74|         3|              A|        F|  Midlands|        East|      Tin|     0.01|       8|        0|        0|\n",
      "| 3328|     13|    62|        32|              D|        M|     North|      N East|      Tin|     0.01|       5|        0|        0|\n",
      "| 4529|     10|    62|        49|              F|        M|  Midlands|        East|   Silver|  2038.76|       3|        0|        0|\n",
      "| 5886|     14|    43|        49|              F|        F|      null|        null|     Gold|   6000.0|       1|        1|        1|\n",
      "| 7420|      7|    60|        52|              F|        F|     North|      N East|     Gold|  11000.0|       2|        0|        0|\n",
      "| 9814|      5|  null|        24|              C|        M|South East|      London|   Silver|   5000.0|       1|        1|        1|\n",
      "|10006|      9|    51|        52|              F|        F|  Midlands|    Midlands|   Silver|    300.0|      11|        0|        0|\n",
      "|10219|      6|    64|        19|              C|        F|South East|  S & S East|      Tin|     0.01|       9|        0|        0|\n",
      "|10812|     16|    37|        18|              C|        F|South East|      London|      Tin|     0.01|       4|        1|        2|\n",
      "|11207|      8|    54|        28|              D|        M|  Midlands|    Midlands|   Silver|   1420.0|       1|        0|        0|\n",
      "|11932|      5|    70|        15|              B|        F|  Midlands|    Midlands|     Gold|  6104.66|       8|        0|        0|\n",
      "|14656|   null|    42|        19|              C|        F|  Midlands|        East|      Tin|     0.01|       5|        1|        1|\n",
      "|15350|      7|  null|        40|              E|        F|  Scottish|  C Scotland|      Tin|     0.01|       5|        1|        1|\n",
      "|17302|      7|    49|        28|              D|     null|South East|      London|      Tin|     0.01|       7|        0|        0|\n",
      "+-----+-------+------+----------+---------------+---------+----------+------------+---------+---------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data = spark.read.csv('organics.csv', inferSchema=True, header=True) # read csv data, set inferSchema to be true.\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ID column is not needed for machine learning. The variable DemCluster is a nominal variable that includes too many categories, and we will remove this variable. Target Amount will also be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DemAffl: integer (nullable = true)\n",
      " |-- DemAge: integer (nullable = true)\n",
      " |-- DemClusterGroup: string (nullable = true)\n",
      " |-- DemGender: string (nullable = true)\n",
      " |-- DemReg: string (nullable = true)\n",
      " |-- DemTVReg: string (nullable = true)\n",
      " |-- PromClass: string (nullable = true)\n",
      " |-- PromSpend: double (nullable = true)\n",
      " |-- PromTime: integer (nullable = true)\n",
      " |-- TargetBuy: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- DemAffl: double (nullable = true)\n",
      " |-- DemAge: double (nullable = true)\n",
      " |-- DemClusterGroup: string (nullable = true)\n",
      " |-- DemGender: string (nullable = true)\n",
      " |-- DemReg: string (nullable = true)\n",
      " |-- DemTVReg: string (nullable = true)\n",
      " |-- PromClass: string (nullable = true)\n",
      " |-- PromSpend: double (nullable = true)\n",
      " |-- PromTime: double (nullable = true)\n",
      " |-- TargetBuy: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "data = data.drop('ID','DemCluster','TargetAmt') \n",
    "data.printSchema()\n",
    "data.head(3)\n",
    "for variable in ['DemAffl', 'DemAge','PromTime']:\n",
    "    data = data.withColumn(variable,data[variable].cast(DoubleType()))\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at summary statistics for interval variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+-----------------+\n",
      "|summary|          DemAffl|            DemAge|        PromSpend|         PromTime|\n",
      "+-------+-----------------+------------------+-----------------+-----------------+\n",
      "|  count|            21137|             20713|            22222|            21941|\n",
      "|   mean|8.711832331929791|53.796890841500506|4420.248964089997|6.564605077252632|\n",
      "| stddev|3.421194092206597|13.205780845120188|7559.046597013129|4.657208722596065|\n",
      "|    min|              0.0|              18.0|             0.01|              0.0|\n",
      "|    max|             34.0|              79.0|        296313.85|             39.0|\n",
      "+-------+-----------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interval_variables = ['DemAffl','DemAge', 'PromSpend','PromTime']\n",
    "data.describe(interval_variables).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a variable that will hold interval variables that with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_with_missing = ['DemAffl','DemAge','PromTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performing counts on all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|DemClusterGroup|count|\n",
      "+---------------+-----+\n",
      "|              F| 3949|\n",
      "|           null|  674|\n",
      "|              E| 2607|\n",
      "|              B| 4144|\n",
      "|              U|   54|\n",
      "|              D| 4378|\n",
      "|              C| 4566|\n",
      "|              A| 1850|\n",
      "+---------------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|DemGender|count|\n",
      "+---------+-----+\n",
      "|        F|12148|\n",
      "|     null| 2513|\n",
      "|        M| 5815|\n",
      "|        U| 1746|\n",
      "+---------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|    DemReg|count|\n",
      "+----------+-----+\n",
      "|  Scottish| 1368|\n",
      "|      null|  466|\n",
      "|South East| 8634|\n",
      "|South West|  691|\n",
      "|  Midlands| 6740|\n",
      "|     North| 4323|\n",
      "+----------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|    DemTVReg|count|\n",
      "+------------+-----+\n",
      "|      Ulster|  266|\n",
      "|      N East|  785|\n",
      "|      Border|  203|\n",
      "|      S West|  691|\n",
      "|        null|  465|\n",
      "|      London| 6189|\n",
      "|   Yorkshire| 1443|\n",
      "|        East| 1649|\n",
      "|      N Scot|  329|\n",
      "|      N West| 2096|\n",
      "|  C Scotland|  836|\n",
      "|    Midlands| 3122|\n",
      "|Wales & West| 1703|\n",
      "|  S & S East| 2445|\n",
      "+------------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|PromClass|count|\n",
      "+---------+-----+\n",
      "|      Tin| 6487|\n",
      "| Platinum|  840|\n",
      "|   Silver| 8572|\n",
      "|     Gold| 6323|\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|TargetBuy|count|\n",
      "+---------+-----+\n",
      "|        1| 5504|\n",
      "|        0|16718|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nominal_with_dependent = ['DemClusterGroup', 'DemGender', 'DemReg', 'DemTVReg', 'PromClass', 'TargetBuy']\n",
    "for column in nominal_with_dependent:\n",
    "    data.groupBy(column).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a variable to grab all the categorical variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_with_missing = ['DemClusterGroup', 'DemGender', 'DemReg', 'DemTVReg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Missing value imputation for interval variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to do missing value imputation 1) add a missing value indicator; and 2)replace missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|DemAfflMissing|count|\n",
      "+--------------+-----+\n",
      "|             1| 1085|\n",
      "|             0|21137|\n",
      "+--------------+-----+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|    DemAfflImputed|\n",
      "+-------+------------------+\n",
      "|  count|             22222|\n",
      "|   mean| 8.711832331929804|\n",
      "| stddev|3.3366243422702384|\n",
      "|    min|               0.0|\n",
      "|    max|              34.0|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------------+-----+\n",
      "|DemAgeMissing|count|\n",
      "+-------------+-----+\n",
      "|            1| 1509|\n",
      "|            0|20713|\n",
      "+-------------+-----+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|    DemAgeImputed|\n",
      "+-------+-----------------+\n",
      "|  count|            22222|\n",
      "|   mean|53.79689084149959|\n",
      "| stddev|12.74950444653274|\n",
      "|    min|             18.0|\n",
      "|    max|             79.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+---------------+-----+\n",
      "|PromTimeMissing|count|\n",
      "+---------------+-----+\n",
      "|              1|  281|\n",
      "|              0|21941|\n",
      "+---------------+-----+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|  PromTimeImputed|\n",
      "+-------+-----------------+\n",
      "|  count|            22222|\n",
      "|   mean|6.564605077252632|\n",
      "| stddev|4.627668213674665|\n",
      "|    min|              0.0|\n",
      "|    max|             39.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.feature import Imputer\n",
    "for variable in interval_with_missing:\n",
    "    # step 1. add a missing indicator: \n",
    "    indicator_name = variable+\"Missing\" # The variable name of the missing value indictor \n",
    "    data = data.withColumn(indicator_name, f.when(f.isnull(data[variable]),1).otherwise(0))\n",
    "    # do value count to verify.\n",
    "    data.groupBy(indicator_name).count().show()\n",
    "    # step 2: replace missing values with the mean\n",
    "    imputed_name = variable + \"Imputed\" # The variable name of the imputed variable\n",
    "    imputer = Imputer(strategy='mean', inputCols=[variable], outputCols=[imputed_name])\n",
    "    imputer_model = imputer.fit(data)\n",
    "    data = imputer_model.transform(data)\n",
    "    # run the describe to check whether the missing values has been imputed. The count of the imputed variables should be 22222.\n",
    "    data.describe(imputed_name).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Missing value imputation for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DemGender column contains \"M\", \"F\", \"U\", and null. It is understood that \"U\" means unknown. So missing values for gender will be replaced with U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|DemClusterGroup|count|\n",
      "+---------------+-----+\n",
      "|              F| 3949|\n",
      "|        unknown|  674|\n",
      "|              E| 2607|\n",
      "|              B| 4144|\n",
      "|              U|   54|\n",
      "|              D| 4378|\n",
      "|              C| 4566|\n",
      "|              A| 1850|\n",
      "+---------------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|DemGender|count|\n",
      "+---------+-----+\n",
      "|        F|12148|\n",
      "|        M| 5815|\n",
      "|        U| 4259|\n",
      "+---------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|    DemReg|count|\n",
      "+----------+-----+\n",
      "|  Scottish| 1368|\n",
      "|   unknown|  466|\n",
      "|South East| 8634|\n",
      "|South West|  691|\n",
      "|  Midlands| 6740|\n",
      "|     North| 4323|\n",
      "+----------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|    DemTVReg|count|\n",
      "+------------+-----+\n",
      "|      Ulster|  266|\n",
      "|      N East|  785|\n",
      "|      Border|  203|\n",
      "|     unknown|  465|\n",
      "|      S West|  691|\n",
      "|      London| 6189|\n",
      "|   Yorkshire| 1443|\n",
      "|        East| 1649|\n",
      "|      N Scot|  329|\n",
      "|      N West| 2096|\n",
      "|  C Scotland|  836|\n",
      "|    Midlands| 3122|\n",
      "|Wales & West| 1703|\n",
      "|  S & S East| 2445|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for variable in nominal_with_missing:\n",
    "    # if variable is DemGender, replace the missing values in the column with 'U'\n",
    "    if variable == 'DemGender':\n",
    "        # the method fillna can be used to replace missing values with a new value. \n",
    "        data = data.fillna({variable:'U'})\n",
    "    # for the other variable, replace the missing values in the column with 'unknown'\n",
    "    else:\n",
    "        data = data.fillna({variable:'unknown'})\n",
    "    # run value_count to verify:\n",
    "    data.groupBy(variable).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Categorical variable encoding:\n",
    "#### Machine learning algorithms cannot deal with categorical features (i.e., features with strings). So, code will be written to convert the categorical variables with strings into nominal variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------+-------------+---------------+----------------+\n",
      "|DemClusterGroupIndexed|DemGenderIndexed|DemRegIndexed|DemTVRegIndexed|PromClassIndexed|\n",
      "+----------------------+----------------+-------------+---------------+----------------+\n",
      "|                   0.0|             2.0|          1.0|            4.0|             2.0|\n",
      "|                   1.0|             2.0|          1.0|            4.0|             2.0|\n",
      "|                   1.0|             0.0|          1.0|            4.0|             0.0|\n",
      "|                   3.0|             1.0|          1.0|            1.0|             1.0|\n",
      "|                   5.0|             0.0|          1.0|            1.0|             1.0|\n",
      "|                   1.0|             2.0|          2.0|            3.0|             3.0|\n",
      "|                   5.0|             0.0|          1.0|            5.0|             1.0|\n",
      "|                   1.0|             1.0|          2.0|            8.0|             1.0|\n",
      "|                   3.0|             1.0|          1.0|            5.0|             0.0|\n",
      "|                   3.0|             0.0|          5.0|           10.0|             2.0|\n",
      "|                   3.0|             0.0|          2.0|            8.0|             2.0|\n",
      "|                   0.0|             1.0|          0.0|            0.0|             0.0|\n",
      "|                   3.0|             0.0|          1.0|            1.0|             0.0|\n",
      "|                   0.0|             0.0|          0.0|            2.0|             1.0|\n",
      "|                   0.0|             0.0|          0.0|            0.0|             1.0|\n",
      "|                   1.0|             1.0|          1.0|            1.0|             0.0|\n",
      "|                   2.0|             0.0|          1.0|            1.0|             2.0|\n",
      "|                   0.0|             0.0|          1.0|            5.0|             1.0|\n",
      "|                   4.0|             0.0|          3.0|            7.0|             1.0|\n",
      "|                   1.0|             2.0|          0.0|            0.0|             1.0|\n",
      "+----------------------+----------------+-------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "nominal_with_string = ['DemClusterGroup', 'DemGender', 'DemReg', 'DemTVReg', 'PromClass']\n",
    "for variable in nominal_with_string:\n",
    "    indexed_variable = variable+\"Indexed\" # The variable name of the indexed/encoded variable\n",
    "    indexer = StringIndexer(inputCol=variable, outputCol=indexed_variable)\n",
    "    indexer_model = indexer.fit(data)\n",
    "    data = indexer_model.transform(data)\n",
    "data.select('DemClusterGroupIndexed', 'DemGenderIndexed', 'DemRegIndexed', 'DemTVRegIndexed', 'PromClassIndexed').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. Dummy Coding:\n",
    "#### Since categorical variables with strings have been converted into nominal variables with indexes, dummy coding will now be implemented for categories greater than two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------+----------------+------------------+-------------------+\n",
      "|DemClusterGroupIndexedVec|DemGenderIndexedVec|DemRegIndexedVec|DemTVRegIndexedVec|PromClassIndexedVec|\n",
      "+-------------------------+-------------------+----------------+------------------+-------------------+\n",
      "|            (7,[0],[1.0])|          (2,[],[])|   (5,[1],[1.0])|    (13,[4],[1.0])|      (3,[2],[1.0])|\n",
      "|            (7,[1],[1.0])|          (2,[],[])|   (5,[1],[1.0])|    (13,[4],[1.0])|      (3,[2],[1.0])|\n",
      "|            (7,[1],[1.0])|      (2,[0],[1.0])|   (5,[1],[1.0])|    (13,[4],[1.0])|      (3,[0],[1.0])|\n",
      "|            (7,[3],[1.0])|      (2,[1],[1.0])|   (5,[1],[1.0])|    (13,[1],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[5],[1.0])|      (2,[0],[1.0])|   (5,[1],[1.0])|    (13,[1],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[1],[1.0])|          (2,[],[])|   (5,[2],[1.0])|    (13,[3],[1.0])|          (3,[],[])|\n",
      "|            (7,[5],[1.0])|      (2,[0],[1.0])|   (5,[1],[1.0])|    (13,[5],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[1],[1.0])|      (2,[1],[1.0])|   (5,[2],[1.0])|    (13,[8],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[3],[1.0])|      (2,[1],[1.0])|   (5,[1],[1.0])|    (13,[5],[1.0])|      (3,[0],[1.0])|\n",
      "|            (7,[3],[1.0])|      (2,[0],[1.0])|       (5,[],[])|   (13,[10],[1.0])|      (3,[2],[1.0])|\n",
      "|            (7,[3],[1.0])|      (2,[0],[1.0])|   (5,[2],[1.0])|    (13,[8],[1.0])|      (3,[2],[1.0])|\n",
      "|            (7,[0],[1.0])|      (2,[1],[1.0])|   (5,[0],[1.0])|    (13,[0],[1.0])|      (3,[0],[1.0])|\n",
      "|            (7,[3],[1.0])|      (2,[0],[1.0])|   (5,[1],[1.0])|    (13,[1],[1.0])|      (3,[0],[1.0])|\n",
      "|            (7,[0],[1.0])|      (2,[0],[1.0])|   (5,[0],[1.0])|    (13,[2],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[0],[1.0])|      (2,[0],[1.0])|   (5,[0],[1.0])|    (13,[0],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[1],[1.0])|      (2,[1],[1.0])|   (5,[1],[1.0])|    (13,[1],[1.0])|      (3,[0],[1.0])|\n",
      "|            (7,[2],[1.0])|      (2,[0],[1.0])|   (5,[1],[1.0])|    (13,[1],[1.0])|      (3,[2],[1.0])|\n",
      "|            (7,[0],[1.0])|      (2,[0],[1.0])|   (5,[1],[1.0])|    (13,[5],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[4],[1.0])|      (2,[0],[1.0])|   (5,[3],[1.0])|    (13,[7],[1.0])|      (3,[1],[1.0])|\n",
      "|            (7,[1],[1.0])|          (2,[],[])|   (5,[0],[1.0])|    (13,[0],[1.0])|      (3,[1],[1.0])|\n",
      "+-------------------------+-------------------+----------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "# a list of nominal variables that needs to be dummy coded.\n",
    "indexed_nominal_variables = ['DemClusterGroupIndexed', 'DemGenderIndexed', 'DemRegIndexed', 'DemTVRegIndexed', 'PromClassIndexed']\n",
    "for variable in indexed_nominal_variables:\n",
    "    dummy_variable = variable+\"Vec\"\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[variable],\n",
    "                                    outputCols=[dummy_variable])\n",
    "    model = encoder.fit(data)\n",
    "    data = model.transform(data)\n",
    "data.select('DemClusterGroupIndexedVec', 'DemGenderIndexedVec', 'DemRegIndexedVec', 'DemTVRegIndexedVec', 'PromClassIndexedVec').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DemAffl: double (nullable = true)\n",
      " |-- DemAge: double (nullable = true)\n",
      " |-- DemClusterGroup: string (nullable = false)\n",
      " |-- DemGender: string (nullable = false)\n",
      " |-- DemReg: string (nullable = false)\n",
      " |-- DemTVReg: string (nullable = false)\n",
      " |-- PromClass: string (nullable = true)\n",
      " |-- PromSpend: double (nullable = true)\n",
      " |-- PromTime: double (nullable = true)\n",
      " |-- TargetBuy: integer (nullable = true)\n",
      " |-- DemAfflMissing: integer (nullable = false)\n",
      " |-- DemAfflImputed: double (nullable = true)\n",
      " |-- DemAgeMissing: integer (nullable = false)\n",
      " |-- DemAgeImputed: double (nullable = true)\n",
      " |-- PromTimeMissing: integer (nullable = false)\n",
      " |-- PromTimeImputed: double (nullable = true)\n",
      " |-- DemClusterGroupIndexed: double (nullable = false)\n",
      " |-- DemGenderIndexed: double (nullable = false)\n",
      " |-- DemRegIndexed: double (nullable = false)\n",
      " |-- DemTVRegIndexed: double (nullable = false)\n",
      " |-- PromClassIndexed: double (nullable = false)\n",
      " |-- DemClusterGroupIndexedVec: vector (nullable = true)\n",
      " |-- DemGenderIndexedVec: vector (nullable = true)\n",
      " |-- DemRegIndexedVec: vector (nullable = true)\n",
      " |-- DemTVRegIndexedVec: vector (nullable = true)\n",
      " |-- PromClassIndexedVec: vector (nullable = true)\n",
      "\n",
      "['DemAffl', 'DemAge', 'DemClusterGroup', 'DemGender', 'DemReg', 'DemTVReg', 'PromClass', 'PromSpend', 'PromTime', 'TargetBuy', 'DemAfflMissing', 'DemAfflImputed', 'DemAgeMissing', 'DemAgeImputed', 'PromTimeMissing', 'PromTimeImputed', 'DemClusterGroupIndexed', 'DemGenderIndexed', 'DemRegIndexed', 'DemTVRegIndexed', 'PromClassIndexed', 'DemClusterGroupIndexedVec', 'DemGenderIndexedVec', 'DemRegIndexedVec', 'DemTVRegIndexedVec', 'PromClassIndexedVec']\n"
     ]
    }
   ],
   "source": [
    "# look at the schema of data again\n",
    "data.printSchema()\n",
    "# print all the variable in the dataframe\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Construct the Features Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list that includes all the independent variable we need to use in the machine learing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = [\n",
    "                         'DemAfflMissing',\n",
    "                         'DemAfflImputed',\n",
    "                         'DemAgeMissing',\n",
    "                         'DemAgeImputed',\n",
    "                         'DemClusterGroupIndexedVec',\n",
    "                         'DemGenderIndexedVec',\n",
    "                         'DemRegIndexedVec',\n",
    "                         'DemTVRegIndexedVec',\n",
    "                         'PromClassIndexedVec',\n",
    "                         'PromSpend',\n",
    "                         'PromTimeMissing',\n",
    "                         'PromTimeImputed'\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLlib expects data to be represented in two columns: a features vector and a label column. Code can be used to prepare the features vector using assembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DemAffl=10.0, DemAge=76.0, DemClusterGroup='C', DemGender='U', DemReg='Midlands', DemTVReg='Wales & West', PromClass='Gold', PromSpend=16000.0, PromTime=4.0, TargetBuy=0, DemAfflMissing=0, DemAfflImputed=10.0, DemAgeMissing=0, DemAgeImputed=76.0, PromTimeMissing=0, PromTimeImputed=4.0, DemClusterGroupIndexed=0.0, DemGenderIndexed=2.0, DemRegIndexed=1.0, DemTVRegIndexed=4.0, PromClassIndexed=2.0, DemClusterGroupIndexedVec=SparseVector(7, {0: 1.0}), DemGenderIndexedVec=SparseVector(2, {}), DemRegIndexedVec=SparseVector(5, {1: 1.0}), DemTVRegIndexedVec=SparseVector(13, {4: 1.0}), PromClassIndexedVec=SparseVector(3, {2: 1.0}), features=SparseVector(37, {1: 10.0, 3: 76.0, 4: 1.0, 14: 1.0, 22: 1.0, 33: 1.0, 34: 16000.0, 36: 4.0})),\n",
       " Row(DemAffl=4.0, DemAge=49.0, DemClusterGroup='D', DemGender='U', DemReg='Midlands', DemTVReg='Wales & West', PromClass='Gold', PromSpend=6000.0, PromTime=5.0, TargetBuy=0, DemAfflMissing=0, DemAfflImputed=4.0, DemAgeMissing=0, DemAgeImputed=49.0, PromTimeMissing=0, PromTimeImputed=5.0, DemClusterGroupIndexed=1.0, DemGenderIndexed=2.0, DemRegIndexed=1.0, DemTVRegIndexed=4.0, PromClassIndexed=2.0, DemClusterGroupIndexedVec=SparseVector(7, {1: 1.0}), DemGenderIndexedVec=SparseVector(2, {}), DemRegIndexedVec=SparseVector(5, {1: 1.0}), DemTVRegIndexedVec=SparseVector(13, {4: 1.0}), PromClassIndexedVec=SparseVector(3, {2: 1.0}), features=SparseVector(37, {1: 4.0, 3: 49.0, 5: 1.0, 14: 1.0, 22: 1.0, 33: 1.0, 34: 6000.0, 36: 5.0}))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=independent_variables, outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Training vs. test dataset partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting your data into a training (70%) and a test dataset (30%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7,0.3], seed=12345) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Classifcation: Training with Gradient-boosted tree classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "algo = GBTClassifier(featuresCol='features', labelCol='TargetBuy', maxIter=10)\n",
    "model = algo.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Make predictions using the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+\n",
      "|TargetBuy|prediction|         probability|\n",
      "+---------+----------+--------------------+\n",
      "|        1|       0.0|[0.56852197122020...|\n",
      "|        0|       0.0|[0.56852197122020...|\n",
      "|        0|       0.0|[0.56852197122020...|\n",
      "|        0|       0.0|[0.56352291718998...|\n",
      "|        0|       0.0|[0.80963655609518...|\n",
      "|        0|       0.0|[0.86020671789026...|\n",
      "|        0|       0.0|[0.86020671789026...|\n",
      "|        1|       0.0|[0.56352291718998...|\n",
      "|        0|       0.0|[0.56852197122020...|\n",
      "|        1|       0.0|[0.56852197122020...|\n",
      "|        1|       0.0|[0.56352291718998...|\n",
      "|        0|       0.0|[0.81882667437565...|\n",
      "|        0|       0.0|[0.80963655609518...|\n",
      "|        0|       0.0|[0.81882667437565...|\n",
      "|        0|       0.0|[0.80963655609518...|\n",
      "|        0|       0.0|[0.56352291718998...|\n",
      "|        1|       0.0|[0.80963655609518...|\n",
      "|        0|       0.0|[0.80963655609518...|\n",
      "|        0|       0.0|[0.81882667437565...|\n",
      "|        0|       0.0|[0.86020671789026...|\n",
      "+---------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.select(['TargetBuy','prediction','probability']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In MLlib the default metric used for evaluating classification models is area_under_roc (auc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8227046558924439"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using spark ml to do model evaluation \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='TargetBuy', metricName='areaUnderROC')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation with SciKit-Learn\n",
    "### Next, please write code to use scikit-learn to create the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      5049\n",
      "           1       0.70      0.42      0.53      1684\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      6733\n",
      "   macro avg       0.76      0.68      0.70      6733\n",
      "weighted avg       0.80      0.81      0.79      6733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(['TargetBuy']).collect()\n",
    "y_pred = predictions.select(['prediction']).collect()\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like model is roughly 80% accurate in predicting if someone will buy organic products. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
